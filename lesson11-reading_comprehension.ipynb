{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Comprehension /Question Answering\n",
    "\n",
    "Code for the Attention reader describe in the paper: https://arxiv.org/pdf/1606.02858v2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change your path here\n",
    "PATH = Path(\"/data2/yinterian/reading_comprehension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "Get the data from here https://cs.nyu.edu/~kcho/DMQA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtraining\u001b[0m/  \u001b[01;34mvalidation\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls $PATH/data/cnn/questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = PATH/\"data/cnn/questions/training\"\n",
    "valid_path = PATH/\"data/cnn/questions/validation\"\n",
    "train_questions = list(Path(train_path).glob('*.question'))\n",
    "valid_questions = list(Path(valid_path).glob('*.question'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380298, 3924)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_questions), len(valid_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/8914bf26caeb006f46972fc09b6d54157f11c9a9.question'),\n",
       " PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/8c95933a89ed1868c0a0c6b8eff519d71b9278f2.question'),\n",
       " PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/2f97a8b7e4a2566bfafce1657a7ae3430ea873bf.question'),\n",
       " PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/bc06dc9ba6b2e06961f0d147f80533e044aa8dbb.question'),\n",
       " PosixPath('/data2/yinterian/reading_comprehension/data/cnn/questions/training/700864902e8c607caf14bb436946cc74ecb5cef8.question')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this data has already been cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://web.archive.org/web/20150421065616id_/http://www.cnn.com/2015/01/02/politics/clinton-aide-white-house/\r\n",
      "\r\n",
      "@entity0 ( @entity1 ) the @entity4 administration 's top aide in charge of promoting @entity7 enrollment is leaving the @entity8 , possibly with eyes on helping another @entity10 win the job in 2016 . @entity12 , an aide to @entity14 's 2008 presidential campaign , is leaving the @entity8 to rejoin 270 strategies , a @entity17 consulting firm he helped found . \" i am thrilled today to announce i will be returning to the management team of 270 strategies , \" @entity12 , who served as deputy director of the @entity19 , said in a statement . \" i want to thank the president for the opportunity to serve and senior advisor @entity25 for being an amazing boss and mentor . \" word of @entity12 's departure from the @entity8 had been rumored for months , both inside and outside 270 strategies . @entity30 reported in december that he was thought to rejoin the consulting firm and the @entity32 broke the story friday morning . the now former @entity8 aide is close with @entity35 , an operative who many @entity17 see as the frontrunner for @entity38 's 2016 campaign manager job . @entity35 and @entity12 worked together on @entity38 and @entity4 's 2008 campaigns and share a small group of confidants and friends . if @entity43 is tapped for the top campaign job , @entity12 is expected to get a top position , too . the @entity46 oddly played out last year when emails for a group of people - the self - proclaimed \" @entity51 \" -- were leaked to @entity50 . in them , @entity12 -- who refers to himself as \" reverend \" - congratulated friends working on campaigns for \" crushing it mafia style . \" \" @entity58 . @entity51 till i die , \" @entity12 wrote in one email obtained by @entity50 . \" if you have just a few minutes , hop on that activate and punish those voters ! \" @entity12 said he was returning to 270 strategies because of the group 's commitment to \" doing big things and having a meaningful impact on the issues and communities we care about . \" \" it was our deep - seated belief that grassroots organizing is a necessary component to making change in those communities , \" @entity12 said . \" today , the 270 mission is stronger than ever , and i could not be more excited to rejoin the team . \"\r\n",
      "\r\n",
      "he is close with the man widely seen as the frontrunner to lead @placeholder 's possible 2016 campaign\r\n",
      "\r\n",
      "@entity38\r\n",
      "\r\n",
      "@entity17:Democratic\r\n",
      "@entity30:Buzzfeed\r\n",
      "@entity1:CNN\r\n",
      "@entity0:Washington\r\n",
      "@entity7:Obamacare\r\n",
      "@entity12:Marshall\r\n",
      "@entity4:Obama\r\n",
      "@entity38:Clinton\r\n",
      "@entity10:Democrat\r\n",
      "@entity46:Mook-Marshall\r\n",
      "@entity19:White House Office of Public Engagement\r\n",
      "@entity51:Mafia\r\n",
      "@entity50:ABC\r\n",
      "@entity25:Valerie Jarrett\r\n",
      "@entity32:Washington Post\r\n",
      "@entity43:Mook\r\n",
      "@entity35:Mook\r\n",
      "@entity14:Hillary Clinton\r\n",
      "@entity58:F U Republicans\r\n",
      "@entity8:White House"
     ]
    }
   ],
   "source": [
    "! cat $PATH/data/cnn/questions/training/55482c04581f3c7ca514c55f71c45230bdf4c824.question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_question(in_file):    \n",
    "    documents = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    num_examples = 0\n",
    "    f = open(in_file, 'r')\n",
    "    lines = f.readlines()\n",
    "    document = lines[2].strip()\n",
    "    question = lines[4].strip()\n",
    "    answer = lines[6].strip()\n",
    "    assert(\"@placeholder\" in question)\n",
    "    assert(\"@entity\" in answer)\n",
    "    f.close()\n",
    "    return document, question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def relabeling(document, question, answer):\n",
    "    \n",
    "    q_words = question.split(' ')\n",
    "    d_words = document.split(' ')\n",
    "    assert answer in d_words\n",
    "    \n",
    "\n",
    "    entity_dict = {}\n",
    "    entity_id = 0\n",
    "    for word in d_words + q_words:\n",
    "        if (word.startswith('@entity')) and (word not in entity_dict):\n",
    "            entity_dict[word] = '@entity' + str(entity_id)\n",
    "            entity_id += 1\n",
    "\n",
    "    q_words = [entity_dict[w] if w in entity_dict else w for w in q_words]\n",
    "    d_words = [entity_dict[w] if w in entity_dict else w for w in d_words]\n",
    "    answer = entity_dict[answer]\n",
    "    question = ' '.join(q_words)\n",
    "    document = ' '.join(d_words)\n",
    "\n",
    "    return document, question, answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new imacs sport the latest @entity10 i5 / i7 @placeholder architecture ==> @entity12\n",
      "new imacs sport the latest @entity2 i5 / i7 @placeholder architecture ==> @entity3\n"
     ]
    }
   ],
   "source": [
    "document, question, answer = process_question(train_questions[2])\n",
    "print(question, \"==>\", answer)\n",
    "document, question, answer = relabeling(document, question, answer)\n",
    "print(question, \"==>\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "    documents = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for path in tqdm(paths):\n",
    "        document, question, answer = process_question(path)\n",
    "        document, question, answer = relabeling(document, question, answer)\n",
    "        documents.append(document)\n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "    return documents, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "#documents, questions, answers = load_data(train_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_dict(sentences, max_words=50000):\n",
    "    \"\"\"\n",
    "        Build a dictionary for the words in `sentences`.\n",
    "        Only the max_words ones are kept and the remaining will be mapped to <UNK>.\n",
    "    \"\"\"\n",
    "    word_count = Counter()\n",
    "    for sent in sentences:\n",
    "        for w in sent.split(' '):\n",
    "            word_count[w] += 1\n",
    "\n",
    "    words = word_count.most_common(max_words)\n",
    "    # leave 0 to UNK\n",
    "    # leave 1 to delimiter |||\n",
    "    return {w[0]: index + 2 for (index, w) in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#word_dict = build_dict(documents + questions)\n",
    "#pickle.dump(word_dict, open(PATH/\"word_dict.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "entity_markers = list(set([w for w in word_dict.keys() if w.startswith('@entity')] + answers))\n",
    "entity_markers = ['<unk_entity>'] + entity_markers\n",
    "entity_dict = {w: index for (index, w) in enumerate(entity_markers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(entity_dict)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vectorize(documents, questions, answers, word_dict, entity_dict):\n",
    "    \"\"\"\n",
    "        Vectorize `examples`.\n",
    "        in_x1, in_x2: sequences for document and question respecitvely.\n",
    "        in_y: label\n",
    "        in_l: whether the entity label occurs in the document.\n",
    "    \"\"\"\n",
    "    in_x1 = []\n",
    "    in_x2 = []\n",
    "    in_l = np.zeros((len(documents), len(entity_dict)))\n",
    "    in_y = []\n",
    "    for idx, (d, q, a) in enumerate(zip(documents, questions, answers)):\n",
    "        d_words = d.split(' ')\n",
    "        q_words = q.split(' ')\n",
    "        assert (a in d_words)\n",
    "        seq1 = [word_dict[w] if w in word_dict else 0 for w in d_words]\n",
    "        seq2 = [word_dict[w] if w in word_dict else 0 for w in q_words]\n",
    "        if (len(seq1) > 0) and (len(seq2) > 0):\n",
    "            in_x1.append(seq1)\n",
    "            in_x2.append(seq2)\n",
    "            in_l[idx, [entity_dict[w] for w in d_words if w in entity_dict]] = 1.0\n",
    "            in_y.append(entity_dict[a] if a in entity_dict else 0)\n",
    "\n",
    "    return in_x1, in_x2, in_l, in_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_x1, train_x2, train_l, train_y = vectorize(documents, questions, answers, word_dict, entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[327, 2021, 5, 5863, 96, 62, 2, 4119, 7529, 11, 4801]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78f016048194f07ab8c0d12bef20fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3924.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "documents, questions, answers = load_data(valid_questions)\n",
    "valid_x1, valid_x2, valid_l, valid_y = vectorize(documents, questions, answers, word_dict, entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96, 480, 504, 306, 10, 7200]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dict = {\"x1\": train_x1, \"x2\": train_x2, \"l\": train_l, \"y\": train_y}\n",
    "valid_dict = {\"x1\": valid_x1, \"x2\": valid_x2, \"l\": valid_l, \"y\": valid_y}\n",
    "pickle.dump(train_dict, open(PATH/\"train_dict.pickle\", 'wb'))\n",
    "pickle.dump(valid_dict, open(PATH/\"valid_dict.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = pickle.load(open(PATH/\"train_dict.pickle\", \"rb\"))\n",
    "valid_dict  = pickle.load(open(PATH/\"valid_dict.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = pickle.load(open(PATH/\"word_dict.pickle\", 'rb'))\n",
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380298, 3924)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dict[\"y\"]), len(valid_dict[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, d_dict):\n",
    "        self.d_dict = d_dict \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.d_dict[\"y\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.d_dict[\"x1\"][idx], self.d_dict[\"x2\"][idx], self.d_dict[\"l\"][idx], self.d_dict[\"y\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = QADataset(train_dict)\n",
    "valid_ds = QADataset(valid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall:\n",
    "* `x1` tokens from document\n",
    "* `x2` tokens from question\n",
    "* `l` entities present in the document\n",
    "* `y` answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, l, y = train_ds[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1069, 19.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x1), l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([59, 14, 1063, 685, 42, 96, 327, 5, 1439, 2039, 13, 2, 346], 153)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamic padding\n",
    "def collate_fn(batch):\n",
    "    x1 = [torch.LongTensor(sample[0]) for sample in batch] \n",
    "    x2 = [torch.LongTensor(sample[1]) for sample in batch] \n",
    "    L = torch.LongTensor([sample[2] for sample in batch])\n",
    "    y = torch.LongTensor([sample[3] for sample in batch])\n",
    "    x1lens = np.array([len(seq) for seq in x1])\n",
    "    x2lens = np.array([len(seq) for seq in x2])\n",
    "    \n",
    "    # pad the batch\n",
    "    padded_x1 = torch.zeros(len(x1), x1lens.max()).long()\n",
    "    for idx, length in enumerate(x1lens):\n",
    "        padded_x1[idx, x1lens.max() - length:] = x1[idx]\n",
    "    \n",
    "    padded_x2 = torch.zeros(len(x2), x2lens.max()).long()\n",
    "    for idx, length in enumerate(x2lens):\n",
    "        padded_x2[idx, x2lens.max() - length:] = x2[idx]\n",
    "    \n",
    "    return (padded_x1, padded_x2, L, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [train_ds[0], train_ds[1], train_ds[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, l, y = collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1184]),\n",
       " torch.Size([3, 13]),\n",
       " torch.Size([3, 328]),\n",
       " tensor([ 94, 187, 187]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x2.shape, l.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Debugging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=3, shuffle=False, collate_fn=collate_fn)\n",
    "x1, x2, l, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb = nn.Embedding(vocab_size, 10, padding_idx=0)\n",
    "gru1 = nn.GRU(10, 7, batch_first=True)\n",
    "gru2 = nn.GRU(10, 5, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1184, 10]) torch.Size([3, 12, 10])\n"
     ]
    }
   ],
   "source": [
    "x1 = emb(x1)\n",
    "x2 = emb(x2)\n",
    "print(x1.shape, x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1184, 7]), torch.Size([3, 5]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts1, ht1 = gru1(x1)\n",
    "hts2, ht2 = gru2(x2)\n",
    "hts1.shape, ht2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note this is just a matrix multiplication\n",
    "liner_att = nn.Linear(7, 5, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1184, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wp = liner_att(hts1)\n",
    "Wp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = ht2[0].unsqueeze(2)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1184, 1]), torch.Size([3, 1184]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qWp = torch.bmm(Wp, q)\n",
    "qWp.shape, qWp[:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alpha = F.softmax(qWp, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1184, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1184, 7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = (alpha*hts1).sum(1)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear_out = nn.Linear(7, 328, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 328])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = linear_out(o)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 328])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# masking entities that do not appear in the document\n",
    "out2 = out*l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7445, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(out2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveReader(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size=vocab_size, emb_dim=100, hidden_dim=50, output_dim=328):\n",
    "        super(AttentiveReader, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.gruD = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.gruQ = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.linear_att = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x1, x2, l):\n",
    "        x1 = self.emb(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        x2 = self.emb(x2)\n",
    "        x2 = self.dropout(x2)\n",
    "        hts, _ = self.gruD(x1)\n",
    "        _, q = self.gruQ(x2)\n",
    "        Wp = self.linear_att(hts)\n",
    "        q = self.bn1(q[0])\n",
    "        qWp = torch.bmm(Wp, q.unsqueeze(2))\n",
    "        alpha = F.softmax(qWp, dim=1)\n",
    "        o = (alpha*hts).sum(1)\n",
    "        o = self.bn2(o) ## try also F.relu\n",
    "        out = self.linear_out(o)\n",
    "        return l*out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=1000, shuffle=False, collate_fn=collate_fn)\n",
    "x1, x2, l, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7947, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x1, x2, l)\n",
    "F.cross_entropy(out, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_segment(start_lr, end_lr, iterations):\n",
    "    i = np.arange(iterations)\n",
    "    c_i = 1 + np.cos(i*np.pi/iterations)\n",
    "    return end_lr + (start_lr - end_lr)/2 *c_i\n",
    "\n",
    "def get_cosine_triangular_lr(max_lr, iterations):\n",
    "    min_start, min_end = max_lr/5, max_lr/5\n",
    "    iter1 = int(0.2*iterations)\n",
    "    iter2 = iterations - iter1\n",
    "    segs = [cosine_segment(min_start, max_lr, iter1), cosine_segment(max_lr, min_end, iter2)]\n",
    "    return np.concatenate(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 10000\n",
    "lr = get_cosine_triangular_lr(0.005, N)\n",
    "plt.plot(list(range(N)), lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, train_dl, valid_dl, optimizer, epochs=10, num_hidden=50, max_lr=0.005):\n",
    "    iterations = epochs*len(train_dl)\n",
    "    pbar = tqdm(total=iterations)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    best_acc = 0\n",
    "    ind = 0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x1, x2, l, y in train_dl:\n",
    "            update_optimizer(optimizer, lrs[ind])\n",
    "            x1 = x1.cuda()\n",
    "            x2 = x2.cuda()\n",
    "            l = l.cuda()\n",
    "            y = y.cuda()\n",
    "            y_pred = model(x1, x2, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "            pbar.update()\n",
    "            ind +=1\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"epoch % d train loss %.3f val loss %.3f and val accuracy %.3f\" % (\n",
    "            i, sum_loss/total, val_loss, val_acc))\n",
    "        if val_acc > best_acc:\n",
    "            path = \"{0}/models/model_att_acc_{1}_{2:.0f}.pth\".format(PATH, num_hidden, 100*val_acc) \n",
    "            save_model(model, path)\n",
    "            best_acc = val_acc\n",
    "            print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x1, x2, l, y in valid_dl:\n",
    "        x1 = x1.cuda()\n",
    "        x2 = x2.cuda()\n",
    "        l = l.cuda()\n",
    "        y = y.cuda()\n",
    "        y_hat = model(x1, x2, l)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        preds = torch.max(y_hat, dim=1)[1]\n",
    "        correct += (preds==y).float().sum().item()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "hidden_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2e35dc335e45c68a9905aa0f3d663e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 train loss 3.527 val loss 2.255 and val accuracy 0.370\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_37.pth\n",
      "epoch  1 train loss 1.989 val loss 1.674 and val accuracy 0.549\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_55.pth\n",
      "epoch  2 train loss 1.640 val loss 1.446 and val accuracy 0.615\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_61.pth\n",
      "epoch  3 train loss 1.434 val loss 1.317 and val accuracy 0.645\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_65.pth\n",
      "epoch  4 train loss 1.313 val loss 1.292 and val accuracy 0.656\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_66.pth\n",
      "epoch  5 train loss 1.232 val loss 1.263 and val accuracy 0.664\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_66.pth\n",
      "epoch  6 train loss 1.169 val loss 1.243 and val accuracy 0.669\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_67.pth\n",
      "epoch  7 train loss 1.117 val loss 1.233 and val accuracy 0.671\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_67.pth\n",
      "epoch  8 train loss 1.068 val loss 1.251 and val accuracy 0.673\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_67.pth\n",
      "epoch  9 train loss 1.023 val loss 1.264 and val accuracy 0.670\n",
      "epoch  10 train loss 0.982 val loss 1.269 and val accuracy 0.668\n",
      "epoch  11 train loss 0.942 val loss 1.264 and val accuracy 0.675\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_68.pth\n",
      "epoch  12 train loss 0.902 val loss 1.266 and val accuracy 0.676\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_68.pth\n",
      "epoch  13 train loss 0.865 val loss 1.273 and val accuracy 0.676\n",
      "epoch  14 train loss 0.832 val loss 1.300 and val accuracy 0.677\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_68.pth\n",
      "epoch  15 train loss 0.801 val loss 1.306 and val accuracy 0.676\n",
      "epoch  16 train loss 0.776 val loss 1.314 and val accuracy 0.678\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_68.pth\n",
      "epoch  17 train loss 0.753 val loss 1.331 and val accuracy 0.673\n",
      "epoch  18 train loss 0.735 val loss 1.336 and val accuracy 0.677\n",
      "epoch  19 train loss 0.722 val loss 1.349 and val accuracy 0.668\n"
     ]
    }
   ],
   "source": [
    "model = AttentiveReader(hidden_dim=128).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=20, num_hidden=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf6ec75843e4e3c81c2d639498a4390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11430.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 train loss 3.524 val loss 2.156 and val accuracy 0.387\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_39.pth\n",
      "epoch  1 train loss 2.044 val loss 1.755 and val accuracy 0.520\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_52.pth\n",
      "epoch  2 train loss 1.716 val loss 1.543 and val accuracy 0.584\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_58.pth\n",
      "epoch  3 train loss 1.524 val loss 1.393 and val accuracy 0.630\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_63.pth\n",
      "epoch  4 train loss 1.387 val loss 1.296 and val accuracy 0.657\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_66.pth\n",
      "epoch  5 train loss 1.293 val loss 1.266 and val accuracy 0.662\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_66.pth\n",
      "epoch  6 train loss 1.219 val loss 1.262 and val accuracy 0.663\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_66.pth\n",
      "epoch  7 train loss 1.161 val loss 1.249 and val accuracy 0.672\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_67.pth\n",
      "epoch  8 train loss 1.114 val loss 1.263 and val accuracy 0.674\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_67.pth\n",
      "epoch  9 train loss 1.070 val loss 1.258 and val accuracy 0.670\n",
      "epoch  10 train loss 1.032 val loss 1.232 and val accuracy 0.683\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_68.pth\n",
      "epoch  11 train loss 0.993 val loss 1.263 and val accuracy 0.685\n",
      "/data2/yinterian/reading_comprehension/models/model_att_acc_128_69.pth\n",
      "epoch  12 train loss 0.957 val loss 1.269 and val accuracy 0.677\n",
      "epoch  13 train loss 0.923 val loss 1.289 and val accuracy 0.679\n",
      "epoch  14 train loss 0.888 val loss 1.284 and val accuracy 0.676\n",
      "epoch  15 train loss 0.856 val loss 1.305 and val accuracy 0.676\n",
      "epoch  16 train loss 0.826 val loss 1.321 and val accuracy 0.682\n",
      "epoch  17 train loss 0.795 val loss 1.331 and val accuracy 0.678\n",
      "epoch  18 train loss 0.765 val loss 1.346 and val accuracy 0.680\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fce1bd0f393b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentiveReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_epocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-2e77e2ff0f60>\u001b[0m in \u001b[0;36mtrain_epocs\u001b[0;34m(model, train_dl, valid_dl, optimizer, epochs, num_hidden, max_lr)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AttentiveReader(hidden_dim=128).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReader(hidden_dim=128).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=128, max_lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReader(hidden_dim=128).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=128, max_lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1400\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReaderBN(hidden_dim=50).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=20, num_hidden=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReader(hidden_dim=50).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentiveReaderBN(hidden_dim=50).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_epocs(model, train_dl, valid_dl, optimizer, epochs=30, num_hidden=50, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model v2\n",
    "* We need bidirectional LSTMs\n",
    "* Initialize with pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://arxiv.org/pdf/1606.02858v2.pdf\n",
    "* https://github.com/danqi/rc-cnn-dailymail\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
